/**
 * å‘é€æ¶ˆæ¯åˆ°è®¯é£APIè¿›è¡Œå¤„ç†ã€‚
 * @param {Array} inputVal - è¦å‘é€çš„è¾“å…¥æ¶ˆæ¯ã€‚
 * @returns {Promise<string>} - ä¸€ä¸ªè§£æä¸ºè®¯é£APIå“åº”çš„Promiseã€‚
 */
import CryptoJS from 'crypto-js'
import dotenv from 'dotenv'
import WebSocket from 'ws'
import { tokensLimit } from '../../config.js'
import { imageUnderstanding } from './imageunderstanding.js'
import path from 'path'
import process from 'process'
import { FileBox } from 'file-box'
import { exec, execSync } from 'child_process'
import { recognizeAudio } from './voicerecog.js'

const env = dotenv.config().parsed // ç¯å¢ƒå‚æ•°
// APPIDï¼ŒAPISecretï¼ŒAPIKeyåœ¨https://console.xfyun.cn/services/cbmè¿™é‡Œè·å–
// æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹WebAPIæ–‡æ¡£:https://www.xfyun.cn/doc/spark/Web.html
// SDK&APIé”™è¯¯ç æŸ¥è¯¢:https://www.xfyun.cn/document/error-code?code=
const appID = env.XUNFEI_APP_ID
const apiKey = env.XUNFEI_API_KEY
const apiSecret = env.XUNFEI_API_SECRET
// åœ°å€å¿…é¡»å¡«å†™ï¼Œä»£è¡¨ç€å¤§æ¨¡å‹çš„ç‰ˆæœ¬å·ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
const httpUrl = new URL('https://spark-api.xf-yun.com/v3.5/chat')

let modelDomain // V1.1-V3.5åŠ¨æ€è·å–ï¼Œé«˜äºä»¥ä¸Šç‰ˆæœ¬æ‰‹åŠ¨æŒ‡å®š

function authenticate() {
  // console.log(httpUrl.pathname)
  // åŠ¨æ€è·å–domainä¿¡æ¯
  switch (httpUrl.pathname) {
    case '/v1.1/chat':
      modelDomain = 'general'
      break
    case '/v2.1/chat':
      modelDomain = 'generalv2'
      break
    case '/v3.1/chat':
      modelDomain = 'generalv3'
      break
    case '/v3.5/chat':
      modelDomain = 'generalv3.5'
      break
  }

  return new Promise((resolve, reject) => {
    let url = 'wss://' + httpUrl.host + httpUrl.pathname

    let host = 'localhost:8080'
    let date = new Date().toGMTString()
    let algorithm = 'hmac-sha256'
    let headers = 'host date request-line'
    let signatureOrigin = `host: ${host}\ndate: ${date}\nGET ${httpUrl.pathname} HTTP/1.1`
    let signatureSha = CryptoJS.HmacSHA256(signatureOrigin, apiSecret)
    let signature = CryptoJS.enc.Base64.stringify(signatureSha)
    let authorizationOrigin = `api_key="${apiKey}", algorithm="${algorithm}", headers="${headers}", signature="${signature}"`
    let authorization = btoa(authorizationOrigin)
    url = `${url}?authorization=${authorization}&date=${date}&host=${host}`
    resolve(url)
  })
}

/**
 * å‘é€æ¶ˆæ¯åˆ°è®¯é£aiæ¥å£è·å–å›å¤ã€‚
 * @param {Array} inputVal - è¾“å…¥çš„æ¶ˆæ¯æ•°ç»„ã€‚
 * @returns {Promise<Object>} - ä¸€ä¸ªè§£æä¸ºè®¯é£æ¥å£å“åº”çš„Promiseã€‚
 */
export async function xunfeiSendMsg(inputVal) {
  /**
   * Handles image messages.
   * @param {Object} lastUserMessage - The last user message object.
   * @returns {Promise<string>} - A promise that resolves to the response from image understanding API.
   */
  async function handleImageMessage(lastUserMessage) {
    console.log('å‘ç°å›¾ç‰‡æ¶ˆæ¯', lastUserMessage)
    const imagePath = path.join(process.cwd(), lastUserMessage.content.match(/\{(.*)\}/)[1])
    //console.log(imagePath)
    return imageUnderstanding(imagePath, env.IMAGE_UNDERSTANDING_PROMPT)
  }

  async function handleVoiceMessage(lastUserMessage) {
    console.log('å‘ç°è¯­éŸ³æ¶ˆæ¯', lastUserMessage)

    const voicePath = path.join(process.cwd(), lastUserMessage.content.match(/\{(.*)\}/)[1])

    const pcmFilePath = await sil2pcm(voicePath)

    return recognizeAudio(pcmFilePath)
  }

  // åˆ›å»ºä¸€ä¸ªPromise
  let messagePromise = new Promise(async (resolve, reject) => {
    // ç›‘å¬websocketçš„å„é˜¶æ®µäº‹ä»¶ å¹¶åšç›¸åº”å¤„ç†
    let payloadText =
      // æ³¨æ„ï¼štexté‡Œé¢çš„æ‰€æœ‰contentå†…å®¹åŠ ä¸€èµ·çš„tokenséœ€è¦æ§åˆ¶åœ¨8192ä»¥å†…ï¼Œå¼€å‘è€…å¦‚æœ‰è¾ƒé•¿å¯¹è¯éœ€æ±‚ï¼Œéœ€è¦é€‚å½“è£å‰ªå†å²ä¿¡æ¯
      [
        { role: 'system', content: env.SYSTEM_PROMPT },
        // { role: 'user', content: 'å¤šä½¿ç”¨è¡¨æƒ…ç¬¦å·å’Œæˆ‘èŠå¤©' },
        // { role: 'assistant', content: 'å¥½çš„,æˆ‘ä¼šå¤šç”¨è¡¨æƒ…ç¬¦å·çš„. æ¯”å¦‚ğŸ˜„' },
      ]
    payloadText.push(...inputVal)
    const lastUserMessage = payloadText[payloadText.length - 1]
    // Extracted method to handle image messages

    // If the last message is an image message, call the image understanding API
    if (lastUserMessage.content.includes('[å›¾ç‰‡æ¶ˆæ¯]')) {
      // å¦‚æœæ˜¯å›¾ç‰‡ç›´æ¥è¿”å›è¯†åˆ«ç»“æœ,ä¸å‚ä¸å¯¹è¯
      const response = await handleImageMessage(lastUserMessage)
      resolve({ orignalMessage: lastUserMessage.content, convertedMessage: response, response: response })
      return
    }
    // å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯è¯­éŸ³æ¶ˆæ¯ï¼Œè°ƒç”¨è¯­éŸ³ç†è§£æ¥å£
    if (lastUserMessage.content.includes('[è¯­éŸ³æ¶ˆæ¯]')) {
      // æ›¿æ¢æœ€åä¸€æ¡æ¶ˆæ¯ä¸ºè¯­éŸ³è¯†åˆ«ç»“æœ
      payloadText.pop()
      payloadText.push({ role: 'user', content: await handleVoiceMessage(lastUserMessage) })
    }

    //payloadText æ„é€ å®Œæˆ,å¼€å§‹å‘é€

    console.log('payloadText to submit', payloadText)

    // è¿™å‡ å¥æ”¾åœ¨å‡½æ•°å¤–é¢å°±ä¼šå¯¼è‡´å‘è¯­éŸ³çš„æ—¶å€™è«åå¡æ­», æ”¾åœ¨è¿™é‡Œå°±æ˜¯æ­£å¸¸çš„
    // æ€€ç–‘è·Ÿ socket çš„ç”Ÿå‘½å‘¨æœŸæœ‰å…³
    // å’¨è¯¢äº† ai, æ˜¯å› ä¸º websocket æ˜¯å¼‚æ­¥çš„, æ‰§è¡Œäº†ä¹‹åå†è¿è¡Œè€—æ—¶è¾ƒé•¿çš„ä»£ç ,è¿™æ—¶å€™å·²ç»æ‰“å¼€äº†,å¯¼è‡´ open event æ— æ³•è§¦å‘
    let myUrl = await authenticate()
    let total_res = '' // è¯·ç©ºå›ç­”å†å²
    let socket = new WebSocket(String(myUrl))

    socket.addEventListener('open', (event) => {
      console.log('socketå¼€å¯è¿æ¥')
      // å‘é€æ¶ˆæ¯
      let params = {
        header: {
          app_id: appID,
          uid: 'fd3f47e4-d',
        },
        parameter: {
          chat: {
            domain: modelDomain,
            temperature: 0.8,
            top_k: 4,
            max_tokens: tokensLimit,
          },
        },
        payload: {
          message: {
            // å¦‚æœæƒ³è·å–ç»“åˆä¸Šä¸‹æ–‡çš„å›ç­”ï¼Œéœ€è¦å¼€å‘è€…æ¯æ¬¡å°†å†å²é—®ç­”ä¿¡æ¯ä¸€èµ·ä¼ ç»™æœåŠ¡ç«¯ï¼Œå¦‚ä¸‹ç¤ºä¾‹
            // æ³¨æ„ï¼štexté‡Œé¢çš„æ‰€æœ‰contentå†…å®¹åŠ ä¸€èµ·çš„tokenséœ€è¦æ§åˆ¶åœ¨8192ä»¥å†…ï¼Œå¼€å‘è€…å¦‚æœ‰è¾ƒé•¿å¯¹è¯éœ€æ±‚ï¼Œéœ€è¦é€‚å½“è£å‰ªå†å²ä¿¡æ¯
            text: payloadText,
          },
        },
      }
      socket.send(JSON.stringify(params))
    })

    socket.addEventListener('message', (event) => {
      let data = JSON.parse(String(event.data))
      total_res += data.payload?.choices?.text?.[0]?.content ?? ''
      console.log(data.payload?.choices?.text?.[0]?.content ?? '')
      if (data.header.code !== 0) {
        console.log('socketå‡ºé”™äº†', data.header.code, ':', data.header.message)
        // å‡ºé”™äº†"æ‰‹åŠ¨å…³é—­è¿æ¥"
        socket.close()
        reject('')
      }
      if (data.header.code === 0) {
        // å¯¹è¯å·²ç»å®Œæˆ
        if (data.payload.choices.text && data.header.status === 2) {
          //total_res += data.payload.choices.text[0].content
          setTimeout(() => {
            // "å¯¹è¯å®Œæˆï¼Œæ‰‹åŠ¨å…³é—­è¿æ¥"
            socket.close()
          }, 1000)
        }
      }
    })

    socket.addEventListener('close', (event) => {
      console.log('socket è¿æ¥å…³é—­')
      // å¯¹è¯å®Œæˆåsocketä¼šå…³é—­ï¼Œå°†èŠå¤©è®°å½•æ¢è¡Œå¤„ç†
      resolve({ orignalMessage: lastUserMessage.content, convertedMessage: payloadText[payloadText.length - 1].content, response: total_res })
    })

    socket.addEventListener('error', (event) => {
      console.log('socketè¿æ¥é”™è¯¯', event)
      reject('')
    })
  })

  return await messagePromise
}

async function sil2pcm(voicePath) {
  const pcmFilePath = voicePath.replace('.sil', '.pcm')

  const ffmpegCommand = `ffmpeg -y -i ${voicePath} -f s16le -acodec pcm_s16le ${pcmFilePath} > /dev/null 2>&1`

  execSync(ffmpegCommand, (error, stdout, stderr) => {
    if (error) {
      console.error(`æ‰§è¡Œffmpegå‘½ä»¤å¤±è´¥: ${error}`)
      return
    }

    console.log(`Silkæ–‡ä»¶å·²æˆåŠŸè½¬æ¢ä¸ºPCMæ ¼å¼: ${pcmFilePath}`)
  })
  return pcmFilePath
}
